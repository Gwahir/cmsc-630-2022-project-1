{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12206a75-9c4e-46ab-9a80-91835ac86b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.lib.stride_tricks as slide\n",
    "import imageio as iio\n",
    "import multiprocessing\n",
    "import re\n",
    "import io\n",
    "import math\n",
    "import glob\n",
    "import tools\n",
    "\n",
    "class Sample:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        classMatch = re.search('[\\\\\\/]([a-zA-Z]+)(\\d+)\\.(\\w+)', path)\n",
    "        self.klass = classMatch.group(1).lower()\n",
    "        self.number = int(classMatch.group(2))\n",
    "        self.extension = classMatch.group(3)\n",
    "        self.klassId = tools.CLASSES.index(self.klass)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'{self.path} {self.klass} {self.number}'\n",
    "    def __repr__(self):\n",
    "        return f'{self.path} {self.klass} {self.number}'\n",
    "        \n",
    "    def readImage(self):\n",
    "        return iio.imread(self.path)\n",
    "    \n",
    "    def writeImage(self, buffer, base, extension):\n",
    "        if not extension:\n",
    "            extension = self.extension\n",
    "        iio.imgwrite(f'{base}/{self.klass}{str(self.number).zfill(3)}.{extension}', buffer)\n",
    "        \n",
    "\n",
    "\n",
    "def buildSampleList(pathGlob):\n",
    "    samples = []\n",
    "    for i, filePath in enumerate(glob.glob(pathGlob)):\n",
    "        samples.append(Sample(filePath))\n",
    "    return samples;\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "828f4734-c258-40ef-b8b5-3eaaaea2c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compareOverlay(base, oppose):\n",
    "    return np.count(base - oppose) / np.count(base)\n",
    "\n",
    "def extractSegmentFeatures(patch, steps = 10):\n",
    "    step = 2.0*math.pi / steps\n",
    "    accum = 0\n",
    "    origSize = np.count_nonzero(patch)\n",
    "    side = np.max(patch.shape)\n",
    "    padding = ((side - patch.shape[0] + side) // 2, (side - patch.shape[1] + side) // 2)\n",
    "    padded = np.pad(patch, padding)\n",
    "    com = scipy.ndimage.center_of_mass(padded)\n",
    "    line = np.zeros(padded.shape)\n",
    "    line[round(com[0])] = 1\n",
    "    perim = np.count_nonzero(padded ^ scipy.ndimage.binary_erosion(padded))\n",
    "    \n",
    "    \n",
    "    \n",
    "    diameters = []\n",
    "    for i in range(steps):\n",
    "        newPatch = scipy.ndimage.rotate(padded, i * step, reshape=False)\n",
    "        accum = accum + np.count_nonzero(padded * newPatch)\n",
    "        diameters.append(np.count_nonzero(newPatch * line))\n",
    "    dMin = np.min(diameters)\n",
    "    dMax = np.max(diameters)\n",
    "    \n",
    "    return [com[0] / patch.shape[0], com[1] / patch.shape[1], accum /  steps, dMin, dMax, dMax / dMin, perim]\n",
    "\n",
    "def averageIntensity(object, patch, gray):\n",
    "    np.mean(gray[object] * patch.astype(np.uint8))\n",
    "    \n",
    "def averageColor(object, patch, color):\n",
    "    np.mean(color[object] * patch.astype(np.uint8), axis=(0,1))\n",
    "\n",
    "def com(patch):\n",
    "    cm = scipy.ndimage.center_of_mass(patch)\n",
    "    return math.sqrt(cm[0] ** 2 + cm[1] ** 2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "50bca5fa-e8d6-4dd7-a55e-7874c4e3ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.pyplot as plot\n",
    "import scipy;\n",
    "samples = buildSampleList('./images/*')\n",
    "\n",
    "def medianFilter(input, kernel, mode='edge'):\n",
    "    slid = tools.slideKernel(input, kernel, mode)\n",
    "    flat = slid.reshape((slid.shape[0], slid.shape[1], slid.shape[2] * slid.shape[3]))\n",
    "    \n",
    "    return np.median(flat, axis=2)\n",
    "\n",
    "\n",
    "#samples = np.random.choice(samples, 20)\n",
    "medianKernel = np.ones((7,7))\n",
    "discMask = tools.makeBooleanDisc(5)\n",
    "\n",
    "def area(sliceT, img):\n",
    "    return np.asarray(img[sliceT]).size\n",
    "    \n",
    "\n",
    "def processAndPlot(sample):\n",
    "    original = sample.readImage()\n",
    "    #buffer = np.zeros(img.shape[0:2], dtype=img.dtype)\n",
    "    \n",
    "    # img = tools.rgbToLuminosity(original)\n",
    "    # img = tools.autoThresholdSegmentation(img)\n",
    "    # img = medianFilter(img, medianKernel)\n",
    "    # img = tools.shrinkAndGrow(img, discMask, steps=3)\n",
    "    # img = tools.growAndShrink(img, discMask, steps=2)\n",
    "    # img = tools.shrinkAndGrow(img, discMask, steps=2)\n",
    "    \n",
    "    gray = tools.rgbToLuminosity(original)\n",
    "    img = scipy.ndimage.median_filter(gray, size=5)\n",
    "    img = tools.autoThresholdSegmentation(img)\n",
    "    #img = tools.shrinkAndGrow(img, discMask, steps=3).astype(np.uint8)\n",
    "    img = scipy.ndimage.binary_erosion(img, discMask, 5)\n",
    "    img = scipy.ndimage.binary_dilation(img, discMask, 5)\n",
    "    \n",
    "    markerSource = scipy.ndimage.binary_erosion(img, discMask, 5)\n",
    "    markers, _ = scipy.ndimage.label(markerSource)\n",
    "    \n",
    "    \n",
    "    img = img.astype(np.uint8)\n",
    "    \n",
    "    # xm, ym = np.ogrid[0:img.shape[0]:10, 0:img.shape[1]:10]\n",
    "    # markers = np.zeros_like(img).astype(np.int16)\n",
    "    # markers[xm, ym]= np.arange(xm.size*ym.size).reshape((xm.size,ym.size))\n",
    "    img = scipy.ndimage.watershed_ift(img, markers)\n",
    "    #img[xm, ym] = img[xm-1, ym-1]\n",
    "    \n",
    "    objects = scipy.ndimage.find_objects(img)\n",
    "    #objects = objects[type(objects) is tuple]\n",
    "    minXLen = 10\n",
    "    minYLen = 10\n",
    "    maxXLen = img.shape[0] // 1.9\n",
    "    maxYLen = img.shape[1] // 1.9\n",
    "    objects = [a for a in objects \n",
    "               if a != None and \n",
    "               (a[0].stop - a[0].start) > minXLen and \n",
    "               (a[0].stop - a[0].start) < maxXLen and \n",
    "               (a[1].stop - a[1].start) > minYLen and \n",
    "               (a[1].stop - a[1].start) < maxYLen]\n",
    "    areas = [(a[0].stop - a[0].start) * (a[1].stop - a[1].start) for a in objects]\n",
    "    areaIndices = np.argsort(areas);\n",
    "    objects = [objects[i] for i in areaIndices]\n",
    "    \n",
    "    if len(objects) > 7:\n",
    "        midIndex = len(objects)//2\n",
    "        objects = objects[midIndex:]\n",
    "        \n",
    "    \n",
    "    patches = [img[obj] for obj in objects]\n",
    "    \n",
    "    \n",
    "    patches = [np.choose(p  == p[p.shape[0]//2, p.shape[1]//2], [0,1]) for p in patches]\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        meanIntensity = np.mean(gray[objects[0]] * patches[0].astype(np.uint8))\n",
    "    except:\n",
    "        meanIntensity = gray[gray.shape[0] // 2, gray.shape[1] // 2]\n",
    "    try:\n",
    "        meanColor = np.mean(original[objects[0]] * tools.intensityToRgb(patches[0].astype(np.uint8)), axis=(0,1))\n",
    "    except:\n",
    "        meanColor = original[original.shape[0] // 2, original.shape[1] // 2]\n",
    "    \n",
    "    features = []\n",
    "    for patch in patches:\n",
    "        meanIntensity = np.mean(gray[objects[0]] * patches[0].astype(np.uint8))\n",
    "        meanColor = np.mean(original[objects[0]] * tools.intensityToRgb(patches[0].astype(np.uint8)), axis=(0,1))\n",
    "        featureVec = extractSegmentFeatures(patch)\n",
    "        featureVec.append(meanIntensity)\n",
    "        featureVec.append(meanColor[0])\n",
    "        featureVec.append(meanColor[1])\n",
    "        featureVec.append(meanColor[2])\n",
    "        featureVec.append(sample.klassId)\n",
    "        if len(features) == 0: \n",
    "            features = np.asarray(featureVec)\n",
    "        else:\n",
    "            features[0] += featureVec[0]\n",
    "            features[1] += featureVec[1]\n",
    "            features[2] = min(features[2], featureVec[2])\n",
    "            features[3] += featureVec[3]\n",
    "            features[4] += featureVec[4]\n",
    "            features[5] += featureVec[5]\n",
    "            features[6] += featureVec[6]\n",
    "            \n",
    "            features[7] += featureVec[7]\n",
    "            features[8] += featureVec[8]\n",
    "            features[9] += featureVec[9]\n",
    "            features[10] += featureVec[10]\n",
    "            \n",
    "            \n",
    "    length = len(patches)\n",
    "    features[0] /= length\n",
    "    features[1] /= length\n",
    "\n",
    "    features[3] /= length\n",
    "    features[4] /= length\n",
    "    features[5] /= length\n",
    "    features[6] /= length\n",
    "    features[7] /= length\n",
    "    features[8] /= length\n",
    "    features[9] /= length\n",
    "    features[10] /= length\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(sample.path + ' original')\n",
    "    plt.imshow(original)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(sample.path)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    for patch in patches:\n",
    "        plt.figure()\n",
    "        plt.imshow(patch, cmap='gray')\n",
    "        \n",
    "    return objects\n",
    "\n",
    "\n",
    "def process(sample):\n",
    "    original = sample.readImage()\n",
    "    #buffer = np.zeros(img.shape[0:2], dtype=img.dtype)\n",
    "    \n",
    "    # img = tools.rgbToLuminosity(original)\n",
    "    # img = tools.autoThresholdSegmentation(img)\n",
    "    # img = medianFilter(img, medianKernel)\n",
    "    # img = tools.shrinkAndGrow(img, discMask, steps=3)\n",
    "    # img = tools.growAndShrink(img, discMask, steps=2)\n",
    "    # img = tools.shrinkAndGrow(img, discMask, steps=2)\n",
    "    \n",
    "    gray = tools.rgbToLuminosity(original)\n",
    "    img = scipy.ndimage.median_filter(gray, size=5)\n",
    "    img = tools.autoThresholdSegmentation(img)\n",
    "    #img = tools.shrinkAndGrow(img, discMask, steps=3).astype(np.uint8)\n",
    "    img = scipy.ndimage.binary_erosion(img, discMask, 5)\n",
    "    img = scipy.ndimage.binary_dilation(img, discMask, 5)\n",
    "    \n",
    "    markerSource = scipy.ndimage.binary_erosion(img, discMask, 5)\n",
    "    markers, _ = scipy.ndimage.label(markerSource)\n",
    "    \n",
    "    \n",
    "    img = img.astype(np.uint8)\n",
    "    \n",
    "    # xm, ym = np.ogrid[0:img.shape[0]:10, 0:img.shape[1]:10]\n",
    "    # markers = np.zeros_like(img).astype(np.int16)\n",
    "    # markers[xm, ym]= np.arange(xm.size*ym.size).reshape((xm.size,ym.size))\n",
    "    img = scipy.ndimage.watershed_ift(img, markers)\n",
    "    #img[xm, ym] = img[xm-1, ym-1]\n",
    "    \n",
    "    objects = scipy.ndimage.find_objects(img)\n",
    "    #objects = objects[type(objects) is tuple]\n",
    "    minXLen = 10\n",
    "    minYLen = 10\n",
    "    maxXLen = img.shape[0] // 1.9\n",
    "    maxYLen = img.shape[1] // 1.9\n",
    "    objects = [a for a in objects \n",
    "               if a != None and \n",
    "               (a[0].stop - a[0].start) > minXLen and \n",
    "               (a[0].stop - a[0].start) < maxXLen and \n",
    "               (a[1].stop - a[1].start) > minYLen and \n",
    "               (a[1].stop - a[1].start) < maxYLen]\n",
    "    areas = [(a[0].stop - a[0].start) * (a[1].stop - a[1].start) for a in objects]\n",
    "    areaIndices = np.argsort(areas);\n",
    "    objects = [objects[i] for i in areaIndices]\n",
    "    \n",
    "    if len(objects) > 7:\n",
    "        #midIndex = len(objects)//2\n",
    "        #objects = objects[midIndex:]\n",
    "        objects = objects[-8:]\n",
    "        \n",
    "    \n",
    "    patches = [img[obj] for obj in objects]\n",
    "    patches = [np.choose(p  == p[p.shape[0]//2, p.shape[1]//2], [0,1]) for p in patches]\n",
    "    \n",
    "    try:\n",
    "        meanIntensity = np.mean(gray[objects[0]] * patches[0].astype(np.uint8))\n",
    "    except:\n",
    "        meanIntensity = gray[gray.shape[0] // 2, gray.shape[1] // 2]\n",
    "    try:\n",
    "        meanColor = np.mean(original[objects[0]] * tools.intensityToRgb(patches[0].astype(np.uint8)), axis=(0,1))\n",
    "    except:\n",
    "        meanColor = original[original.shape[0] // 2, original.shape[1] // 2]\n",
    "    \n",
    "    features = []\n",
    "    for patch in patches:\n",
    "        meanIntensity = np.mean(gray[objects[0]] * patches[0].astype(np.uint8))\n",
    "        meanColor = np.mean(original[objects[0]] * tools.intensityToRgb(patches[0].astype(np.uint8)), axis=(0,1))\n",
    "        featureVec = extractSegmentFeatures(patch)\n",
    "        featureVec.append(meanIntensity)\n",
    "        featureVec.append(meanColor[0])\n",
    "        featureVec.append(meanColor[1])\n",
    "        featureVec.append(meanColor[2])\n",
    "        featureVec.append(sample.klassId)\n",
    "        if len(features) == 0: \n",
    "            features = np.asarray(featureVec)\n",
    "        else:\n",
    "            features[0] += featureVec[0]\n",
    "            features[1] += featureVec[1]\n",
    "            features[2] = min(features[2], featureVec[2])\n",
    "            features[3] += featureVec[3]\n",
    "            features[4] += featureVec[4]\n",
    "            features[5] += featureVec[5]\n",
    "            features[6] += featureVec[6]\n",
    "            \n",
    "            features[7] += featureVec[7]\n",
    "            features[8] += featureVec[8]\n",
    "            features[9] += featureVec[9]\n",
    "            features[10] += featureVec[10]\n",
    "            \n",
    "    if len(features) == 0:\n",
    "        f = np.zeros(12)\n",
    "        f[11] = sample.klassId\n",
    "        return f\n",
    "    \n",
    "    length = len(patches)\n",
    "    features[0] /= length\n",
    "    features[1] /= length\n",
    "\n",
    "    features[3] /= length\n",
    "    features[4] /= length\n",
    "    features[5] /= length\n",
    "    features[6] /= length\n",
    "    features[7] /= length\n",
    "    features[8] /= length\n",
    "    features[9] /= length\n",
    "    features[10] /= length\n",
    "    \n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "9060b088-1110-4a4f-ac7d-c8dca3837f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSamples(samples, fileName = 'data.npy'):\n",
    "    data = []\n",
    "\n",
    "    numSamples = len(samples)\n",
    "    print(f'Number of Samples: {numSamples}')\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        #print(i, sample.path)\n",
    "        data.append(process(sample))\n",
    "        if i % 10 == 0:\n",
    "            print(f'Processed: {i} ({100 * i / numSamples}%)')\n",
    "\n",
    "\n",
    "\n",
    "    np.save(fileName, data, allow_pickle=False)\n",
    "    return data\n",
    "\n",
    "#data = processSamples(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "17930c07-4e8d-4868-8552-142393a97c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10432653061224491,\n",
       " 0.10612244897959185,\n",
       " 0.14224489795918369,\n",
       " 0.20048979591836735,\n",
       " 0.20844897959183672,\n",
       " 0.18832653061224489,\n",
       " 0.18420408163265306,\n",
       " 0.20036734693877553,\n",
       " 0.20036734693877553]"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def kFold(grid, classifier, k=10, stratify=False, param=10):\n",
    "    data = np.copy(grid)\n",
    "    np.random.shuffle(data)\n",
    "    chunks = np.array_split(data, k)\n",
    "    results = []\n",
    "    for i in range(0,k):\n",
    "        src = chunks.copy()\n",
    "        test = src[i]\n",
    "        del src[i]\n",
    "        train = np.concatenate(src)\n",
    "        \n",
    "        correct = 0\n",
    "        for t in test:\n",
    "            if classifier(train, t, param):\n",
    "                correct += 1\n",
    "        results.append(correct / len(test))\n",
    "    return np.mean(results)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "def KNN(train, challenge, k = 10):\n",
    "    ref = np.delete(train, 11, axis=1)\n",
    "    \n",
    "    chal = np.delete(challenge, 11, axis=0)\n",
    "    distance = np.linalg.norm(ref - np.delete(test[2], 11), axis=1)\n",
    "    sortedIndices = np.argsort(distance)\n",
    "    topK = np.concatenate(np.delete([train[i] for i in sortedIndices][-k:], range(11), axis=1)).astype(np.uint8)\n",
    "    result = np.bincount(topK).argmax()\n",
    "    \n",
    "    return result == challenge[11]\n",
    "\n",
    "\n",
    "# d = np.asarray(data)\n",
    "\n",
    "\n",
    "# chunks = np.array_split(d, 10)\n",
    "\n",
    "\n",
    "# train = chunks.copy()\n",
    "# test = train[0]\n",
    "# del train[0]\n",
    "# train = np.concatenate(train)\n",
    "\n",
    "# ref = np.delete(train, 11, axis=1)\n",
    "\n",
    "# distance = np.linalg.norm(ref - np.delete(test[2], 11), axis=1)\n",
    "\n",
    "# sortedIndices = np.argsort(distance)\n",
    "\n",
    "# topK = np.concatenate(np.delete([train[i] for i in sortedIndices][-10:], range(11), axis=1)).astype(np.uint8)\n",
    "\n",
    "# np.bincount(topK).argmax()\n",
    "# test[2]\n",
    "\n",
    "# data = np.load('data.npy')\n",
    "\n",
    "\n",
    "\n",
    "# final = [kFold(data, KNN, param=i) for i in range(5, 50, 5)]\n",
    "\n",
    "# final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "96325dd9-1156-4faa-aa26-bbb3a9cd50e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort([1,4,3,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "9de7d66c-c2f1-4593-91d3-e663030cb146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processSamples(samples, fileName='data3.npy')\n",
    "\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "f69d6cbc-405d-4260-bbec-a96beefcbeed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09424489795918368,\n",
       " 0.10212244897959184,\n",
       " 0.20828571428571427,\n",
       " 0.18240816326530612,\n",
       " 0.2003265306122449,\n",
       " 0.20028571428571426,\n",
       " 0.1823673469387755,\n",
       " 0.16624489795918368,\n",
       " 0.20036734693877553]"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[kFold(np.load('data2.npy'), KNN, param=i) for i in range(5, 50, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d099e3-82f0-4f1f-910b-3b1af3ca4cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
